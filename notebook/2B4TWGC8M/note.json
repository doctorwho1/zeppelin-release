{
  "paragraphs": [
    {
      "text": "%md\n## Magellan: Geospatial Analytics on Spark\nBy [Ram Sriharsha](http://hortonworks.com/blog/author/rsriharsha/)\n\n#### Pre-requisistes\nThis notebook requires Spark 1.4.1\n\n#### Introduction\nGeospatial data is pervasive—in mobile devices, sensors, logs, and wearables. This data’s spatial context is an important variable in many predictive analytics applications.\n\nTo benefit from spatial context in a predictive analytics application, we need to be able to parse geospatial datasets at scale, join them with target datasets that contain point in space information, and answer geometrical queries efficiently.\n\nUnfortunately, if you are working with geospatial data and big data sets that need spatial context, there are limited open source tools that make it easy for you to parse and efficiently query spatial datasets at scale. This poses significant challenges for leveraging geospatial data in business intelligence and predictive analytics applications.\n\nThis is the problem that [Magellan](https://github.com/harsha2010/magellan) sets out to solve. Magellan is an open source library for Geospatial Analytics that uses [Apache Spark](http://spark.apache.org/) as the underlying execution engine. Magellan facilitates geospatial queries and builds upon Spark to solve hard problems of dealing with geospatial data at scale.\n\nIn this notebook, we will introduce the problem of geospatial analytics and show how Magellan allows users to ingest geospatial data and run spatial queries at scale.\n\nTo do so, we will analyze the problem of using Uber data to examine the flow of uber traffic in the city of San Francisco.",
      "dateUpdated": "Oct 25, 2015 2:32:33 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "tableHide": false,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763066523_1596045350",
      "id": "20151025-015106_840181723",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eMagellan: Geospatial Analytics on Spark\u003c/h2\u003e\n\u003cp\u003eBy \u003ca href\u003d\"http://hortonworks.com/blog/author/rsriharsha/\"\u003eRam Sriharsha\u003c/a\u003e\u003c/p\u003e\n\u003ch4\u003ePre-requisistes\u003c/h4\u003e\n\u003cp\u003eThis notebook requires Spark 1.4.1\u003c/p\u003e\n\u003ch4\u003eIntroduction\u003c/h4\u003e\n\u003cp\u003eGeospatial data is pervasive—in mobile devices, sensors, logs, and wearables. This data’s spatial context is an important variable in many predictive analytics applications.\u003c/p\u003e\n\u003cp\u003eTo benefit from spatial context in a predictive analytics application, we need to be able to parse geospatial datasets at scale, join them with target datasets that contain point in space information, and answer geometrical queries efficiently.\u003c/p\u003e\n\u003cp\u003eUnfortunately, if you are working with geospatial data and big data sets that need spatial context, there are limited open source tools that make it easy for you to parse and efficiently query spatial datasets at scale. This poses significant challenges for leveraging geospatial data in business intelligence and predictive analytics applications.\u003c/p\u003e\n\u003cp\u003eThis is the problem that \u003ca href\u003d\"https://github.com/harsha2010/magellan\"\u003eMagellan\u003c/a\u003e sets out to solve. Magellan is an open source library for Geospatial Analytics that uses \u003ca href\u003d\"http://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e as the underlying execution engine. Magellan facilitates geospatial queries and builds upon Spark to solve hard problems of dealing with geospatial data at scale.\u003c/p\u003e\n\u003cp\u003eIn this notebook, we will introduce the problem of geospatial analytics and show how Magellan allows users to ingest geospatial data and run spatial queries at scale.\u003c/p\u003e\n\u003cp\u003eTo do so, we will analyze the problem of using Uber data to examine the flow of uber traffic in the city of San Francisco.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 1:51:06 AM",
      "dateStarted": "Oct 25, 2015 2:32:33 AM",
      "dateFinished": "Oct 25, 2015 2:32:33 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Mapping the flow of Uber traffic in San Francisco with Magellan\nUber has published a dataset of GPS coordinates of [all trips within San Francisco](https://raw.githubusercontent.com/dima42/uber-gps-analysis/master/gpsdata/all.tsv).\n\nOur goal in this example is to join the Uber dataset with the [San Francisco neighborhoods dataset](http://www.arcgis.com/home/item.html?id\u003d3b2a461c2c7848899b7b4cbfa9ebdb67)) to obtain some interesting insights into the patterns of Uber trips in San Francisco.\n\nMagellan has both Scala and Python bindings. In this blog post we use  the Scala APIs.\nMagellan is a Spark Package, and can be included into Zeppelin as below:",
      "dateUpdated": "Oct 25, 2015 2:11:15 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763221863_-1140290472",
      "id": "20151025-015341_1752661711",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003eMapping the flow of Uber traffic in San Francisco with Magellan\u003c/h4\u003e\n\u003cp\u003eUber has published a dataset of GPS coordinates of \u003ca href\u003d\"https://raw.githubusercontent.com/dima42/uber-gps-analysis/master/gpsdata/all.tsv\"\u003eall trips within San Francisco\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOur goal in this example is to join the Uber dataset with the \u003ca href\u003d\"http://www.arcgis.com/home/item.html?id\u003d3b2a461c2c7848899b7b4cbfa9ebdb67\"\u003eSan Francisco neighborhoods dataset\u003c/a\u003e) to obtain some interesting insights into the patterns of Uber trips in San Francisco.\u003c/p\u003e\n\u003cp\u003eMagellan has both Scala and Python bindings. In this blog post we use  the Scala APIs.\n\u003cbr  /\u003eMagellan is a Spark Package, and can be included into Zeppelin as below:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 1:53:41 AM",
      "dateStarted": "Oct 25, 2015 2:11:16 AM",
      "dateFinished": "Oct 25, 2015 2:11:16 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Import Magellan from maven",
      "text": "%dep\nz.addRepo(\"Spark Packages Repo\").url(\"http://dl.bintray.com/spark-packages/maven\")\nz.load(\"com.esri.geometry:esri-geometry-api:1.2.1\")\nz.load(\"harsha2010:magellan:1.0.3-s_2.10\")",
      "dateUpdated": "Oct 25, 2015 2:11:16 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445761734505_353006497",
      "id": "20151025-012854_1186772690",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "res1: org.apache.zeppelin.spark.dep.Dependency \u003d org.apache.zeppelin.spark.dep.Dependency@7c4bd48\n"
      },
      "dateCreated": "Oct 25, 2015 1:28:54 AM",
      "dateStarted": "Oct 25, 2015 2:11:17 AM",
      "dateFinished": "Oct 25, 2015 2:11:21 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Import datasets and upload to HDFS",
      "text": "%sh\nmkdir magellan\nwget https://www.dropbox.com/s/98yz5j6fc4qph3v/all.tsv -P magellan/ -nv\nwget https://www.dropbox.com/s/ttp3kyr9l8hzjdz/planning_neighborhoods.zip -P magellan/ -nv\nunzip magellan/planning_neighborhoods.zip -d magellan/\nhadoop fs -put magellan .\nhadoop fs -ls magellan",
      "dateUpdated": "Oct 25, 2015 1:57:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445761744630_-2051289379",
      "id": "20151025-012904_1717377650",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "2015-10-25 01:48:20 URL:https://dl.dropboxusercontent.com/content_link/boAcNV0LO3ylxIfmKJf8kR44Jaen3rk21rDD6UzMldXp2w5B0j81ClprWSTAYskp/file [60947802/60947802] -\u003e \"magellan/all.tsv\" [1]\n2015-10-25 01:48:21 URL:https://dl.dropboxusercontent.com/content_link/NmsiQZ6j1ASyuo4HH4Ibg2nMLgbqzsOTZmXJzQUv9Zzgg3IVaMkNzLSlEalywhme/file [163771/163771] -\u003e \"magellan/planning_neighborhoods.zip\" [1]\nArchive:  magellan/planning_neighborhoods.zip\n  inflating: magellan/planning_neighborhoods.dbf  \n  inflating: magellan/planning_neighborhoods.shx  \n  inflating: magellan/planning_neighborhoods.shp.xml  \n  inflating: magellan/planning_neighborhoods.shp  \n  inflating: magellan/planning_neighborhoods.sbx  \n  inflating: magellan/planning_neighborhoods.sbn  \n  inflating: magellan/planning_neighborhoods.prj  \nFound 9 items\n-rw-r--r--   3 zeppelin zeppelin   60947802 2015-10-25 01:48 magellan/all.tsv\n-rw-r--r--   3 zeppelin zeppelin       1028 2015-10-25 01:48 magellan/planning_neighborhoods.dbf\n-rw-r--r--   3 zeppelin zeppelin        567 2015-10-25 01:48 magellan/planning_neighborhoods.prj\n-rw-r--r--   3 zeppelin zeppelin        516 2015-10-25 01:48 magellan/planning_neighborhoods.sbn\n-rw-r--r--   3 zeppelin zeppelin        164 2015-10-25 01:48 magellan/planning_neighborhoods.sbx\n-rw-r--r--   3 zeppelin zeppelin     214576 2015-10-25 01:48 magellan/planning_neighborhoods.shp\n-rw-r--r--   3 zeppelin zeppelin      21958 2015-10-25 01:48 magellan/planning_neighborhoods.shp.xml\n-rw-r--r--   3 zeppelin zeppelin        396 2015-10-25 01:48 magellan/planning_neighborhoods.shx\n-rw-r--r--   3 zeppelin zeppelin     163771 2015-10-25 01:48 magellan/planning_neighborhoods.zip\n"
      },
      "dateCreated": "Oct 25, 2015 1:29:04 AM",
      "dateStarted": "Oct 25, 2015 1:48:09 AM",
      "dateFinished": "Oct 25, 2015 1:48:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Spark imports",
      "text": "import magellan.{Point, Polygon, PolyLine}\nimport magellan.coord.NAD83\nimport org.apache.spark.sql.magellan.MagellanContext\nimport org.apache.spark.sql.magellan.dsl.expressions._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._",
      "dateUpdated": "Oct 25, 2015 2:11:43 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440092130_1110348593",
      "id": "20151021-080812_605865139",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import magellan.{Point, Polygon, PolyLine}\nimport magellan.coord.NAD83\nimport org.apache.spark.sql.magellan.MagellanContext\nimport org.apache.spark.sql.magellan.dsl.expressions._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._\n"
      },
      "dateCreated": "Oct 21, 2015 8:08:12 AM",
      "dateStarted": "Oct 25, 2015 2:11:43 AM",
      "dateFinished": "Oct 25, 2015 2:12:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLet us create a case class to attach the schema to this Uber Dataset so we can use the DataFrame abstraction to deal with the data.",
      "dateUpdated": "Oct 25, 2015 2:12:09 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763497691_-1119915749",
      "id": "20151025-015817_871979116",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eLet us create a case class to attach the schema to this Uber Dataset so we can use the DataFrame abstraction to deal with the data.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 1:58:17 AM",
      "dateStarted": "Oct 25, 2015 2:12:09 AM",
      "dateFinished": "Oct 25, 2015 2:12:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create case class for Uber dataset",
      "text": "case class UberRecord(tripId: String, timestamp: String, point: Point)",
      "dateUpdated": "Oct 25, 2015 2:12:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440113738_-484789699",
      "id": "20151021-080833_1323347800",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "defined class UberRecord\n"
      },
      "dateCreated": "Oct 21, 2015 8:08:33 AM",
      "dateStarted": "Oct 25, 2015 2:12:10 AM",
      "dateFinished": "Oct 25, 2015 2:12:11 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow we can read the dataset into a dataframe and cache the resulting dataframe.",
      "dateUpdated": "Oct 25, 2015 2:12:19 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763546354_1631500257",
      "id": "20151025-015906_914671593",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNow we can read the dataset into a dataframe and cache the resulting dataframe.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 1:59:06 AM",
      "dateStarted": "Oct 25, 2015 2:12:19 AM",
      "dateFinished": "Oct 25, 2015 2:12:19 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Read Uber dataset into dataframe",
      "text": "val uber \u003d sc.textFile(\"magellan/all.tsv\").map { line \u003d\u003e\nval parts \u003d line.split(\"\\t\" )\nval tripId \u003d parts(0)\nval timestamp \u003d parts(1)\nval point \u003d Point(parts(3).toDouble, parts(2).toDouble)\nUberRecord(tripId, timestamp, point)\n}.\nrepartition(100).\ntoDF().\ncache()",
      "dateUpdated": "Oct 25, 2015 2:13:13 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440128685_-234471406",
      "id": "20151021-080848_729642312",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "uber: org.apache.spark.sql.DataFrame \u003d [tripId: string, timestamp: string, point: poin]\n"
      },
      "dateCreated": "Oct 21, 2015 8:08:48 AM",
      "dateStarted": "Oct 25, 2015 2:13:13 AM",
      "dateFinished": "Oct 25, 2015 2:13:15 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThis dataset contains the trip id, the timestamp and the latitude and longitude of each point on the trip coalesced into a Point data structure.\n\nA Point is the simplest geometric data structure available in Magellan. It represents a two dimensional point, with x and y coordinates. In this case, as is standard in geospatial analysis, the x coordinate refers to the longitude and the y coordinate the latitude.\n\nSince this dataset is not interesting in itself, we need to enrich this dataset by determining which neighborhood each of these points lie in.\n\nTo do so, we will convert the neighborhood dataset into a dataframe as well, assuming the dataset has been downloaded and the path to the dataset is neighborhoods.path.\n\nThis dataset is in what is known as the [ESRI Shapefile format](https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf).\n\nThis is one of the most common formats in which geospatial data is stored. Magellan has a Data Source implementation that understands how to parse ESRI Shapefiles into Shapes and Metadata.",
      "dateUpdated": "Oct 25, 2015 2:13:18 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763646932_-867658388",
      "id": "20151025-020046_206115557",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eThis dataset contains the trip id, the timestamp and the latitude and longitude of each point on the trip coalesced into a Point data structure.\u003c/p\u003e\n\u003cp\u003eA Point is the simplest geometric data structure available in Magellan. It represents a two dimensional point, with x and y coordinates. In this case, as is standard in geospatial analysis, the x coordinate refers to the longitude and the y coordinate the latitude.\u003c/p\u003e\n\u003cp\u003eSince this dataset is not interesting in itself, we need to enrich this dataset by determining which neighborhood each of these points lie in.\u003c/p\u003e\n\u003cp\u003eTo do so, we will convert the neighborhood dataset into a dataframe as well, assuming the dataset has been downloaded and the path to the dataset is neighborhoods.path.\u003c/p\u003e\n\u003cp\u003eThis dataset is in what is known as the \u003ca href\u003d\"https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf\"\u003eESRI Shapefile format\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis is one of the most common formats in which geospatial data is stored. Magellan has a Data Source implementation that understands how to parse ESRI Shapefiles into Shapes and Metadata.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:00:46 AM",
      "dateStarted": "Oct 25, 2015 2:13:18 AM",
      "dateFinished": "Oct 25, 2015 2:13:18 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create MagellanContext",
      "text": "val magellanContext \u003d new MagellanContext(sc)",
      "dateUpdated": "Oct 25, 2015 2:14:18 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440140325_-1659581332",
      "id": "20151021-080900_1112437015",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "magellanContext: org.apache.spark.sql.magellan.MagellanContext \u003d org.apache.spark.sql.magellan.MagellanContext@b79fffa\n"
      },
      "dateCreated": "Oct 21, 2015 8:09:00 AM",
      "dateStarted": "Oct 25, 2015 2:14:18 AM",
      "dateFinished": "Oct 25, 2015 2:14:18 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThere are two columns in this DataFrame: a shape representing the neighborhood which happens to be polygonal, and metadata which is a map of String keys and String values.\n\nMagellan has a Polygon data structure to capture the spatial geometry of a Polygon. A Polygon in Magellan stands for a Polygonal object with zero or more holes.\nMap columns can be exploded into their keys and values to yield the following dataframe:",
      "dateUpdated": "Oct 25, 2015 2:14:24 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763750246_580257348",
      "id": "20151025-020230_2044689047",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eThere are two columns in this DataFrame: a shape representing the neighborhood which happens to be polygonal, and metadata which is a map of String keys and String values.\u003c/p\u003e\n\u003cp\u003eMagellan has a Polygon data structure to capture the spatial geometry of a Polygon. A Polygon in Magellan stands for a Polygonal object with zero or more holes.\n\u003cbr  /\u003eMap columns can be exploded into their keys and values to yield the following dataframe:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:02:30 AM",
      "dateStarted": "Oct 25, 2015 2:14:24 AM",
      "dateFinished": "Oct 25, 2015 2:14:24 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load neighborhoods dataset into DataFrame representing each one as polygon and metadata",
      "text": "val neighborhoods \u003d magellanContext.read.format(\"magellan\").\nload(\"magellan\").\nselect($\"polygon\", $\"metadata\").\ncache()",
      "dateUpdated": "Oct 25, 2015 2:19:17 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440171544_1945192409",
      "id": "20151021-080931_281898278",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "neighborhoods: org.apache.spark.sql.DataFrame \u003d [polygon: pol, metadata: map\u003cstring,string\u003e]\n"
      },
      "dateCreated": "Oct 21, 2015 8:09:31 AM",
      "dateStarted": "Oct 25, 2015 2:19:17 AM",
      "dateFinished": "Oct 25, 2015 2:19:19 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "View sample of neighbourhood DataFrame",
      "text": "neighborhoods.select(explode($\"metadata\").as(Seq(\"k\", \"v\"))).show(5)",
      "dateUpdated": "Oct 25, 2015 2:20:39 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440185987_-804977404",
      "id": "20151021-080945_1330980387",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+----------+--------------------+\n|         k|                   v|\n+----------+--------------------+\n|neighborho|Twin Peaks       ...|\n|neighborho|Pacific Heights  ...|\n|neighborho|Visitacion Valley...|\n|neighborho|Potrero Hill     ...|\n|neighborho|Crocker Amazon   ...|\n+----------+--------------------+\n\n"
      },
      "dateCreated": "Oct 21, 2015 8:09:45 AM",
      "dateStarted": "Oct 25, 2015 2:20:39 AM",
      "dateFinished": "Oct 25, 2015 2:20:43 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow we are getting somewhere: we are able to parse the San Francisco neighborhood dataset, extract its metadata as well as the polygon shapes that represent each neighborhood. \nThe natural next step is to join this dataset with the uber dataset so that each point on the uber trip can be associated with its corresponding neighborhood.  \n\nHere we run into an important spatial query: How do we compute whether a given point (uber location) lies within a given polygon (or neighborhood) ?\n\nMagellan implements th as well as other spatial operators like intersects, intersection, contains, covers etc making it easy to use.\nIn Magellan, to join the Uber dataset with the San Francisco neighborhood dataset, you would issue the following Spark SQL query:",
      "dateUpdated": "Oct 25, 2015 2:21:01 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763816159_-205876600",
      "id": "20151025-020336_1732297633",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNow we are getting somewhere: we are able to parse the San Francisco neighborhood dataset, extract its metadata as well as the polygon shapes that represent each neighborhood.\n\u003cbr  /\u003eThe natural next step is to join this dataset with the uber dataset so that each point on the uber trip can be associated with its corresponding neighborhood.\u003c/p\u003e\n\u003cp\u003eHere we run into an important spatial query: How do we compute whether a given point (uber location) lies within a given polygon (or neighborhood) ?\u003c/p\u003e\n\u003cp\u003eMagellan implements th as well as other spatial operators like intersects, intersection, contains, covers etc making it easy to use.\n\u003cbr  /\u003eIn Magellan, to join the Uber dataset with the San Francisco neighborhood dataset, you would issue the following Spark SQL query:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:03:36 AM",
      "dateStarted": "Oct 25, 2015 2:20:59 AM",
      "dateFinished": "Oct 25, 2015 2:20:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Map Uber Trips to neighborhoods",
      "text": "neighborhoods.\njoin(uber).\nwhere($\"point\" within $\"polygon\").\nselect($\"tripId\", $\"timestamp\", explode($\"metadata\").as(Seq(\"k\", \"v\"))).\nwithColumnRenamed(\"v\", \"neighborhood\").\ndrop(\"k\").\nshow(5)",
      "dateUpdated": "Oct 25, 2015 2:26:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440209587_1902362688",
      "id": "20151021-081009_570116241",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+------+---------+------------+\n|tripId|timestamp|neighborhood|\n+------+---------+------------+\n+------+---------+------------+\n\n"
      },
      "dateCreated": "Oct 21, 2015 8:10:09 AM",
      "dateStarted": "Oct 25, 2015 2:22:04 AM",
      "dateFinished": "Oct 25, 2015 2:22:17 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThis is interesting: According to our calculation, the GPS coordinates representing the Uber dataset do not fall in any of the San Francisco neighborhoods. How can this be?\n\nThis is a good point to pause and think about coordinate systems. We have been using GPS coordinates for the Uber dataset, but haven’t verified the coordinate system that the San Francisco neighborhood dataset has been encoded in.\n\nIt turns out that most datasets published by the US governmental agencies use what is called State Plane coordinates.\n\nMagellan supports translating between different coordinate systems by implementing a transformer interface which takes in Points and outputs Points.\n\nThis covers all conformal transformations which is the set of all transformations that preserve angles.\nIn particular, to translate between WGS84, the GPS standard coordinate system used in the Uber dataset, and NAD83 Zone 403 (state plane), we can use the following in built transformer:",
      "dateUpdated": "Oct 25, 2015 2:04:17 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763847366_-916077097",
      "id": "20151025-020407_503661891",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eThis is interesting: According to our calculation, the GPS coordinates representing the Uber dataset do not fall in any of the San Francisco neighborhoods. How can this be?\u003c/p\u003e\n\u003cp\u003eThis is a good point to pause and think about coordinate systems. We have been using GPS coordinates for the Uber dataset, but haven’t verified the coordinate system that the San Francisco neighborhood dataset has been encoded in.\u003c/p\u003e\n\u003cp\u003eIt turns out that most datasets published by the US governmental agencies use what is called State Plane coordinates.\u003c/p\u003e\n\u003cp\u003eMagellan supports translating between different coordinate systems by implementing a transformer interface which takes in Points and outputs Points.\u003c/p\u003e\n\u003cp\u003eThis covers all conformal transformations which is the set of all transformations that preserve angles.\n\u003cbr  /\u003eIn particular, to translate between WGS84, the GPS standard coordinate system used in the Uber dataset, and NAD83 Zone 403 (state plane), we can use the following in built transformer:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:04:07 AM",
      "dateStarted": "Oct 25, 2015 2:04:13 AM",
      "dateFinished": "Oct 25, 2015 2:04:13 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Translator between Uber and Neighborhood coordinate systems",
      "text": "val transformer: Point \u003d\u003e Point \u003d (point: Point) \u003d\u003e {\nval from \u003d new NAD83(Map(\"zone\" -\u003e 403)).from()\nval p \u003d point.transform(from)\nnew Point(3.28084 * p.x, 3.28084 * p.y)\n}",
      "dateUpdated": "Oct 25, 2015 2:23:41 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440220764_-922078987",
      "id": "20151021-081020_167250911",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "transformer: magellan.Point \u003d\u003e magellan.Point \u003d \u003cfunction1\u003e\n"
      },
      "dateCreated": "Oct 21, 2015 8:10:20 AM",
      "dateStarted": "Oct 25, 2015 2:23:41 AM",
      "dateFinished": "Oct 25, 2015 2:23:41 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nHere we have defined a new transformer that applies the NAD83 transformation for Zone 403 (Northern California) and further scales the points to have units in feet instead of meters.\nThis allows us to enhance the uber dataset by adding a new column, the scaled column representing the coordinates in the NAD83 State Plane Coordinate System:",
      "dateUpdated": "Oct 25, 2015 2:04:48 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763881843_-719223578",
      "id": "20151025-020441_781592444",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eHere we have defined a new transformer that applies the NAD83 transformation for Zone 403 (Northern California) and further scales the points to have units in feet instead of meters.\n\u003cbr  /\u003eThis allows us to enhance the uber dataset by adding a new column, the scaled column representing the coordinates in the NAD83 State Plane Coordinate System:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:04:41 AM",
      "dateStarted": "Oct 25, 2015 2:04:46 AM",
      "dateFinished": "Oct 25, 2015 2:04:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Add translated Coordinates column to Uber dataFrame",
      "text": "val uberTransformed \u003d uber.\nwithColumn(\"nad83\", $\"point\".transform(transformer)).\ncache()",
      "dateUpdated": "Oct 25, 2015 2:24:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440242411_2145954714",
      "id": "20151021-081042_1983405488",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "uberTransformed: org.apache.spark.sql.DataFrame \u003d [tripId: string, timestamp: string, point: poin, nad83: poin]\n"
      },
      "dateCreated": "Oct 21, 2015 8:10:42 AM",
      "dateStarted": "Oct 25, 2015 2:24:58 AM",
      "dateFinished": "Oct 25, 2015 2:24:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow we are ready to perform the join again:",
      "dateUpdated": "Oct 25, 2015 2:05:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763903868_2114113295",
      "id": "20151025-020503_1617259756",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNow we are ready to perform the join again:\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:05:03 AM",
      "dateStarted": "Oct 25, 2015 2:05:07 AM",
      "dateFinished": "Oct 25, 2015 2:05:07 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Map Uber Trips To Neighborhoods",
      "text": "val joined \u003d neighborhoods.\njoin(uberTransformed).\nwhere($\"nad83\" within $\"polygon\").\nselect($\"tripId\", $\"timestamp\", explode($\"metadata\").as(Seq(\"k\", \"v\"))).\nwithColumnRenamed(\"v\", \"neighborhood\").\ndrop(\"k\").\ncache()",
      "dateUpdated": "Oct 25, 2015 2:26:46 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440253040_-455332599",
      "id": "20151021-081053_1128907682",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "joined: org.apache.spark.sql.DataFrame \u003d [tripId: string, timestamp: string, neighborhood: string]\n"
      },
      "dateCreated": "Oct 21, 2015 8:10:53 AM",
      "dateStarted": "Oct 25, 2015 2:25:04 AM",
      "dateFinished": "Oct 25, 2015 2:25:05 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "joined.show(5)",
      "dateUpdated": "Oct 25, 2015 2:25:13 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440262325_976100231",
      "id": "20151021-081102_231185976",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+------+--------------------+--------------------+\n|tripId|           timestamp|        neighborhood|\n+------+--------------------+--------------------+\n| 12478|2007-01-05T04:55:...|Haight Ashbury   ...|\n| 12483|2007-01-07T07:37:...|Mission          ...|\n| 12484|2007-01-02T04:02:...|South of Market  ...|\n| 12487|2007-01-07T04:26:...|Downtown/Civic Ce...|\n| 12489|2007-01-07T03:00:...|Castro/Upper Mark...|\n+------+--------------------+--------------------+\n\n"
      },
      "dateCreated": "Oct 21, 2015 8:11:02 AM",
      "dateStarted": "Oct 25, 2015 2:25:13 AM",
      "dateFinished": "Oct 25, 2015 2:25:15 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nOk, this looks much more reasonable!\nOne interesting question we are now ready to ask is: What are the top few neighborhoods where most Uber trips pass through?",
      "dateUpdated": "Oct 25, 2015 2:05:32 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445763926053_383158642",
      "id": "20151025-020526_1159970756",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eOk, this looks much more reasonable!\n\u003cbr  /\u003eOne interesting question we are now ready to ask is: What are the top few neighborhoods where most Uber trips pass through?\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:05:26 AM",
      "dateStarted": "Oct 25, 2015 2:05:29 AM",
      "dateFinished": "Oct 25, 2015 2:05:29 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Show top neighborhoods where most Uber trips pass through",
      "text": "joined.\ngroupBy($\"neighborhood\").\nagg(countDistinct(\"tripId\").\nas(\"trips\")).\norderBy(col(\"trips\").desc).\nshow(5)",
      "dateUpdated": "Oct 25, 2015 2:28:04 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440273534_-1857575419",
      "id": "20151021-081113_1220870628",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+--------------------+-----+\n|        neighborhood|trips|\n+--------------------+-----+\n|South of Market  ...| 9891|\n|Western Addition ...| 6794|\n|Downtown/Civic Ce...| 6697|\n|Financial Distric...| 6038|\n|Mission          ...| 5620|\n+--------------------+-----+\n\n"
      },
      "dateCreated": "Oct 21, 2015 8:11:13 AM",
      "dateStarted": "Oct 25, 2015 2:28:04 AM",
      "dateFinished": "Oct 25, 2015 2:28:14 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThere are about 24664 trips for which we have neighborhood information, out of which close to 40% of the trips involve SOMA. \nNow if you are an Uber driver, you may just want to hang out around SOMA.",
      "dateUpdated": "Oct 25, 2015 2:28:22 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445440285513_-845270414",
      "id": "20151021-081125_2064619705",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eThere are about 24664 trips for which we have neighborhood information, out of which close to 40% of the trips involve SOMA.\n\u003cbr  /\u003eNow if you are an Uber driver, you may just want to hang out around SOMA.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 21, 2015 8:11:25 AM",
      "dateStarted": "Oct 25, 2015 2:28:20 AM",
      "dateFinished": "Oct 25, 2015 2:28:20 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAs we see, once we add geospatial context to the Uber dataset, we end up with a fascinating array of questions we can ask about the nature of Uber trips in the city of San Francisco.\n\n### Summary\n\nIn this blog post, we have shown how to use Magellan to perform geospatial analysis on Spark.\n\nHopefully this short introduction has demonstrated how easy and elegant it is to incorporate geospatial context in your applications using Magellan.\n\nIn the future, we will go under the hood to examine how Magellan leverages Spark SQL, Data Frames and Catalyst to provide elegant and simple user APIs while ensuring that spatial queries can execute efficiently.\n",
      "dateUpdated": "Oct 25, 2015 2:28:33 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445764101016_1061302910",
      "id": "20151025-020821_915639433",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eAs we see, once we add geospatial context to the Uber dataset, we end up with a fascinating array of questions we can ask about the nature of Uber trips in the city of San Francisco.\u003c/p\u003e\n\u003ch3\u003eSummary\u003c/h3\u003e\n\u003cp\u003eIn this blog post, we have shown how to use Magellan to perform geospatial analysis on Spark.\u003c/p\u003e\n\u003cp\u003eHopefully this short introduction has demonstrated how easy and elegant it is to incorporate geospatial context in your applications using Magellan.\u003c/p\u003e\n\u003cp\u003eIn the future, we will go under the hood to examine how Magellan leverages Spark SQL, Data Frames and Catalyst to provide elegant and simple user APIs while ensuring that spatial queries can execute efficiently.\u003c/p\u003e\n"
      },
      "dateCreated": "Oct 25, 2015 2:08:21 AM",
      "dateStarted": "Oct 25, 2015 2:28:33 AM",
      "dateFinished": "Oct 25, 2015 2:28:33 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445764171206_-151886992",
      "id": "20151025-020931_300901096",
      "dateCreated": "Oct 25, 2015 2:09:31 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "magellan-blog",
  "id": "2B4TWGC8M",
  "angularObjects": {
    "2B3YY3QPW": [],
    "2B3X73X4X": [],
    "2B1T5C27T": [],
    "2B1XV6UTM": [],
    "2B3AV1ZEQ": [],
    "2B36KFP71": [],
    "2B3N9B1TN": [],
    "2B4VPT27K": [],
    "2B1U12Q3B": [],
    "2B3YYH347": [],
    "2B39GZKSM": [],
    "2B3F8GYSD": [],
    "2B1WUH2Z9": [],
    "2B2SCNDZW": []
  },
  "config": {},
  "info": {}
}